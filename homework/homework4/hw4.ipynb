{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5319f3a3-fb2f-43bf-9c36-272636c8e26b",
   "metadata": {},
   "source": [
    "Ben Kahan  \n",
    "DS 210  \n",
    "Homework 4. \n",
    "12 October 2022  \n",
    "Collaborators: None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed9e50-476b-40f2-b6e9-aec9a5fdf6cf",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3822f5-2b7f-4c6a-ba2e-21ea494205f8",
   "metadata": {},
   "source": [
    "For standard `*.txt` files, I use `vim` or `nano` to edit them. However, for `Rust`, I will be using Intellij with the `Rust` plugin.  \n",
    "\n",
    "For version control, I use `git` and GitHub to store my private repositories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f92584-7f08-416f-b3b0-21edea4a41b0",
   "metadata": {},
   "source": [
    "For example: \n",
    "\n",
    "```bash\n",
    "git init \n",
    "mkdir \"homework4\"\n",
    "git add homework4/\n",
    "git commit -m \"hw4 dir initial\"\n",
    "cd homework4/ \n",
    "vim example.txt # edit the file using vim commands\n",
    "git add example.txt \n",
    "git commit -m \"example.txt initial\"\n",
    "git push origin main \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc6f60-7eb6-4b85-9be3-34b61795ed7e",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9829c60b-5fc3-4590-8ed4-fece535be48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rustc 1.64.0 (a55dd71d5 2022-09-19)\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "rustc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36f3f8c-5918-4635-8f3c-0108bcc34ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo 1.64.0 (387270bc7 2022-09-16)\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cargo --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9334db0-b678-41bf-8821-5a6ebfa9bb8d",
   "metadata": {},
   "source": [
    "For Jupyter, I installed the Rust Jupyter kernel from Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15dbc41-05bb-4da1-9b14-b936efdad049",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9865a8-01af-412c-ac33-6eefba94511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae715b0-1643-486b-8c42-30975044de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100\n",
    "x = np.sort(np.random.rand(1,samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a2a1d9-11f0-4534-8d95-793fb22f2dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c80c9b1-e907-43ec-a136-f56e4e6c271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = x.reshape(-1,1)\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174125db-865f-4505-ad4f-6b54dfa68f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_reg = DecisionTreeRegressor(criterion='mse', max_leaf_nodes=6) # depreciated but I haven't updated my system\n",
    "mae_reg = DecisionTreeRegressor(criterion='mae', max_leaf_nodes=6)\n",
    "\n",
    "mse_reg = DecisionTreeRegressor(criterion='squared-error', max_leaf_nodes=6)\n",
    "mae_reg = DecisionTreeRegressor(criterion='absolute-error', max_leaf_nodes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "549dde38-1d6a-492a-a380-3468ea466b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d29728-6051-4be0-8896-535c6c324d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=1 does not match number of samples=100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmse_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m mae_reg\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), f(x))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/tree/_classes.py:366\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    358\u001b[0m check_scalar(\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    360\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_impurity_decrease\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     target_type\u001b[38;5;241m=\u001b[39mnumbers\u001b[38;5;241m.\u001b[39mReal,\n\u001b[1;32m    362\u001b[0m     min_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m does not match number of samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(y), n_samples)\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=1 does not match number of samples=100"
     ]
    }
   ],
   "source": [
    "mse_reg.fit(x.reshape(-1,1), f(x))\n",
    "mae_reg.fit(x.reshape(-1,1), f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969a0a3-5f58-4b7b-b17f-c29a368fbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(0,1,num=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98414acf-47d1-4601-af5d-2751c9371b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_pred = mse_reg.predict(x_test.reshape(-1,1))\n",
    "mae_pred = mae_reg.predict(x_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e29bf-2cae-4a77-a080-7443980a406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, mse_pred, label = \"Mean Squared Error\")\n",
    "plt.plot(x_test, mae_pred, label = \"Minimum Absolute Error\")\n",
    "plt.scatter(x, f(x), label = \"Original Function\")\n",
    "plt.title(\"Comparison of Error in DT\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8b919-be4a-41f4-8def-c4cd648a7be4",
   "metadata": {},
   "source": [
    "The two plots show how the two error predictors diverge. This makes sense given the way these two decision trees handle error. The MSQ reduces the error along mean of it's output space such that the squared differences are reduced.  \n",
    "\n",
    "The differes from th MAE, where MAE reduces the overall error between the predicted data and the input space.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4f23b-bd56-47ff-86ba-613a028b5bbd",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176636e5-18ba-4f8f-9a0c-a84d795faa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sort(np.random.rand(1,samples).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4d5de-5e19-4a9b-be86-8f65e39007e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (np.random.rand()*np.float_power(x,13) + \\\n",
    "            np.random.rand()*np.float_power(x,-.5) + \\\n",
    "            np.random.rand()* np.cos(x) - \\\n",
    "            .5 * np.random.rand() * \\\n",
    "            np.random.normal(size=samples) \\\n",
    "            ).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1e299-77bf-4acd-ad89-503a4e1138cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77df3c-dde5-4fa6-9e80-1d49dcf662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca65561-2c7b-497e-885e-e31b4d0156c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_poly(c,x):\n",
    "    y = np.zeros_like(x)\n",
    "# What does this inner loop do? \n",
    "# ANS: This innerloop indexes for every entry in c\n",
    "# since c, in this context, is the result of numpy.polyfit(),\n",
    "# the method returns a numpy array with the indicies representing\n",
    "# the coefficients of the fit polynomial \n",
    "# thus, the for loop separates each coefficient and: \n",
    "# y = y*x, multiplies itself (y) by x and adds the coefficient \n",
    "# y is an empty array (declared above to alloc mem) \n",
    "# y is then returned which contains the modified entries of the new polynomial\n",
    "    for coeff in c:\n",
    "        y = y * x + coeff\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46f62b-e041-4a7d-848b-e4e5d3f0822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = np.polyfit(x,y,17)\n",
    "over_res = eval_poly(over,x)\n",
    "under = np.polyfit(x,y,2)\n",
    "under_res = eval_poly(under,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82577b-f82f-4bc4-87c4-a0b3656ad54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y, label=\"Standard Function\")\n",
    "plt.plot(x, over_res, label=\"Overfit\", linestyle=\"--\")\n",
    "plt.plot(x, under_res, label=\"Underfit\", linestyle=\":\")\n",
    "plt.legend()\n",
    "plt.figure(figsize=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa077174-e96e-4874-8982-ca40eede448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "underfit_var = np.var(under_res)\n",
    "overfit_var = np.var(over_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549f28b-a829-4c90-9238-7ccaa67291eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x,y):\n",
    "    return ((x-y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d8033-7417-41bc-9fd6-19a1836d1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "underfit_mse = mse(x, under_res)\n",
    "overfit_mse = mse(x, over_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23196f30-fa08-4d07-8b06-96c6f5119a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "underfit_var, underfit_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316d2cf-9080-40fe-8e8c-8832b010b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_var, overfit_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f4050-8262-4786-9ad2-8356135afcd4",
   "metadata": {},
   "source": [
    "We see that the underfitting leads to lower variance (which is expected) and we see greater bias through the mean squared error estimator of the overfit polynomial. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
